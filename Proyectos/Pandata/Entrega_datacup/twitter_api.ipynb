{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"},"colab":{"name":"twitter_api.ipynb","provenance":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"N-U6urSffB9s"},"source":["# Covid-19 Vaccine Sentiment Analysis"]},{"cell_type":"code","metadata":{"id":"jRkIRO_mfB92"},"source":["import os\n","import tweepy as tw\n","import pandas as pd\n","import numpy as np\n","import re\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"VVASvy8UfB93"},"source":["twitter_keys = pd.read_csv('data/twitter_keys.csv') #Twitter API keys"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xlL4zdaAfB94"},"source":["auth = tw.OAuthHandler(twitter_keys.consumer_key[0], twitter_keys.consumer_secret[0])\n","auth.set_access_token(twitter_keys.access_token[0], twitter_keys.access_token_secret[0])\n","api = tw.API(auth, wait_on_rate_limit=True,wait_on_rate_limit_notify=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tR_5leibfB95"},"source":["# Retrieve Data from Twitter API"]},{"cell_type":"code","metadata":{"id":"ct8HDhOefB95","outputId":"de4a51fa-1f6e-4010-e399-43128065660c"},"source":["f_data = pd.DataFrame()\n","places = api.geo_search(query='USA',granularity='country') #Select the country\n","if places:\n","    place_id = places[0].id\n","# Define the search term and the date_since date as variables\n","search_words = \"(#covid OR vaccine OR covid-19 OR pfizer OR moderna OR covid OR #vaccine) -filter:retweets place:%s \" % place_id\n","date_since = \"2020-01-01\" #Aqui se podria aplicar al dia de ayer\n","# Collect tweets\n","tweets = tw.Cursor(api.search,\n","              q=search_words,\n","              lang=\"en\",\n","              since=date_since).items(5000)\n","# Put tweets in a DataFrame\n","for tweet in tweets:\n","    if tweet.place is not None:        \n","        f_data= f_data.append({\n","            'date':tweet.created_at,\n","            'country_code':tweet.place.country_code,\n","            'place_full_name':tweet.place.full_name,\n","            'place_type': tweet.place.place_type,\n","            'place_name':tweet.place.name,\n","            'verified':tweet.user.verified,\n","            'retweets':tweet.retweet_count,\n","            'likes':tweet.favorite_count,\n","            'text':tweet.text\n","        },ignore_index=True) \n","print('Data for US retrieved')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Rate limit reached. Sleeping for: 819\n"],"name":"stderr"},{"output_type":"stream","text":["Data for US retrieved\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5QRjbtqUfB99"},"source":["#Data cleaning\n","f_data.text = f_data.text.str.lower()\n","f_data.text = f_data.text.apply(lambda x:re.sub('@[^\\s]+','',x)) #Remove twitter handlers\n","f_data.text = f_data.text.apply(lambda x:re.sub(r'\\B#\\S+','',x)) #Remove hashtags\n","f_data.text = f_data.text.apply(lambda x:re.sub(r\"http\\S+\", \"\", x)) # Remove URLS\n","f_data.text = f_data.text.apply(lambda x:' '.join(re.findall(r'\\w+', x))) # Remove all the special characters\n","f_data.text = f_data.text.apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', ' ', x)) #remove all single characters\n","f_data.text = f_data.text.apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I)) # Substituting multiple spaces with single space\n","#f_data['date'] = pd.to_datetime(f_data.date).dt.date #Get only date from datetime"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Cflk58ylfB99"},"source":["#Vader Sentiment Analysis\n","f_data['sentiments'] = f_data['text'].apply(lambda x: SIA().polarity_scores(' '.join(re.findall(r'\\w+',x.lower()))))\n","f_data['Positive Sentiment'] = f_data['sentiments'].apply(lambda x: x['pos']) \n","f_data['Neutral Sentiment'] = f_data['sentiments'].apply(lambda x: x['neu'])\n","f_data['Negative Sentiment'] = f_data['sentiments'].apply(lambda x: x['neg'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"iWbUo-O-fB9-"},"source":["#Compare positve and negative sentiments\n","conditions = [\n","    (f_data['Positive Sentiment'] >= f_data['Negative Sentiment']),\n","    (f_data['Negative Sentiment'] >= f_data['Positive Sentiment']),\n","    ]\n","\n","# create a list of the values we want to assign for each condition\n","values = ['Positive', 'Negative']\n","\n","# create a new column and use np.select to assign values to it using our lists as arguments\n","f_data['Sentiment Label']= np.select(conditions, values)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LzDUWDqXfVPH"},"source":["us_cities = pd.read_csv('uscities.csv')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WnYCT79gfVfJ"},"source":["# Data preparation\n","f_data = f_data[f_data.place_type=='city']\n","f_data.drop(columns=['sentiments'],inplace=True)\n","us_cities=us_cities[['city','state_id','state_name','county_name','lat','lng','id']]\n","us_cities['place_full_name']=us_cities['city']+', '+us_cities['state_id']\n","final_df = f_data.merge(us_cities,on='place_full_name',how='left')\n","final_df['date']=pd.to_datetime(final_df['date'])\n","final_df['round_date']=final_df['date'].dt.floor('h') #Fecha por hora utilizada en el dashboard\n","final_df.drop(columns=['id','Positive Sentiment','Neutral Sentiment','Negative Sentiment'],inplace=True)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0ZXDOQgJf4bh"},"source":[""]},{"cell_type":"code","metadata":{"id":"DeZcVwz8fB9_"},"source":["f_data.to_csv('tweets_dashboard.csv',index=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ra0Y8cdafB9_"},"source":[""],"execution_count":null,"outputs":[]}]}